{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5ab843e-26ae-4f12-bb06-d557150d664e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30612494-a6d8-4f92-983a-bcd1524efc96",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to the carriage and ginny closed the door behind him. Students were hanging from the windows nearest them. A great number of faces, both on the train and off, seemed to be turned toward Harry.\n",
      "\n",
      "“Why are they all staring?” demanded Albus as he and rose craned around to look at the other students.\n",
      "\n",
      "“Don't let it worry you,” said Ron. “It's me, I'm extremely famous.”\n",
      "\n",
      "Albus, Rose, Hugo, and Lily laughed. The train began to more, and Harry walked alongside it, watching his son's thin face, already ablaze with excitement. Harry kept smiling and waving, even though it was like a little bereavement, watching his son glide away from him. . . .\n",
      "\n",
      "The last trace of steam evaporated in the autumn air. The train rounded a corner. Harry's hand was still raised in farewell.\n",
      "\n",
      "“He'll be alright,” murmured Ginny.\n",
      "\n",
      "As Harry looked dat her, he lowered his hand absentmindedly and touched the lightning scar on his forehead.\n",
      "\n",
      "“I know he will.”\n",
      "\n",
      "The scar had not pained Harry for nineteen years. All was well.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/harry_potter.txt\", \"r\") as f:\n",
    "    data = f.read()\n",
    "print(data[-1000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95f5a8cb-785e-4418-a1ca-c65ce4776d8b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !\"&'()*,-./0123456789:;<=>?ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}£¦«°»éü˜–—‘’“”•…\n",
      "106\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(data)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec68c91e-b0d4-47e8-84cc-b364fe90c697",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# encoder, decoder lists\n",
    "chidx = {ch: idx for idx, ch in enumerate(chars)}\n",
    "idxch = {idx: ch for idx, ch in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a481f151-9c13-4a03-b9e9-4ecbd3c4ee25",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n"
     ]
    }
   ],
   "source": [
    "print(idxch[29])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c23bc896-1dcd-4eef-8ce8-7805a037c702",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# enc, dec\n",
    "encode = lambda str : [chidx[char] for char in str]\n",
    "decode = lambda num : ''.join([idxch[idx] for idx in num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dda165f-e884-4d77-97a9-220fc811dd7c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[68, 65, 72, 72, 75, 1, 83, 75, 78, 72, 64]\n",
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print(encode('hello world'))\n",
    "print(decode(encode('hello world')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb92a384-028a-4cdc-9299-25b1779242ea",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6285453]) torch.int64\n",
      "tensor([ 80,  75,   1,  80,  68,  65,   1,  63,  61,  78,  78,  69,  61,  67,\n",
      "         65,   1,  61,  74,  64,   1,  67,  69,  74,  74,  85,   1,  63,  72,\n",
      "         75,  79,  65,  64,   1,  80,  68,  65,   1,  64,  75,  75,  78,   1,\n",
      "         62,  65,  68,  69,  74,  64,   1,  68,  69,  73,  11,   1,  47,  80,\n",
      "         81,  64,  65,  74,  80,  79,   1,  83,  65,  78,  65,   1,  68,  61,\n",
      "         74,  67,  69,  74,  67,   1,  66,  78,  75,  73,   1,  80,  68,  65,\n",
      "          1,  83,  69,  74,  64,  75,  83,  79,   1,  74,  65,  61,  78,  65,\n",
      "         79,  80,   1,  80,  68,  65,  73,  11,   1,  29,   1,  67,  78,  65,\n",
      "         61,  80,   1,  74,  81,  73,  62,  65,  78,   1,  75,  66,   1,  66,\n",
      "         61,  63,  65,  79,   9,   1,  62,  75,  80,  68,   1,  75,  74,   1,\n",
      "         80,  68,  65,   1,  80,  78,  61,  69,  74,   1,  61,  74,  64,   1,\n",
      "         75,  66,  66,   9,   1,  79,  65,  65,  73,  65,  64,   1,  80,  75,\n",
      "          1,  62,  65,   1,  80,  81,  78,  74,  65,  64,   1,  80,  75,  83,\n",
      "         61,  78,  64,   1,  36,  61,  78,  78,  85,  11,   0,   0, 102,  51,\n",
      "         68,  85,   1,  61,  78,  65,   1,  80,  68,  65,  85,   1,  61,  72,\n",
      "         72,   1,  79,  80,  61,  78,  69,  74,  67,  28, 103,   1,  64,  65,\n",
      "         73,  61,  74,  64,  65,  64,   1,  29,  72,  62,  81,  79,   1,  61,\n",
      "         79,   1,  68,  65,   1,  61,  74,  64,   1,  78,  75,  79,  65,   1,\n",
      "         63,  78,  61,  74,  65,  64,   1,  61,  78,  75,  81,  74,  64,   1,\n",
      "         80,  75,   1,  72,  75,  75,  71,   1,  61,  80,   1,  80,  68,  65,\n",
      "          1,  75,  80,  68,  65,  78,   1,  79,  80,  81,  64,  65,  74,  80,\n",
      "         79,  11,   0,   0, 102,  32,  75,  74,   5,  80,   1,  72,  65,  80,\n",
      "          1,  69,  80,   1,  83,  75,  78,  78,  85,   1,  85,  75,  81,   9,\n",
      "        103,   1,  79,  61,  69,  64,   1,  46,  75,  74,  11,   1, 102,  37,\n",
      "         80,   5,  79,   1,  73,  65,   9,   1,  37,   5,  73,   1,  65,  84,\n",
      "         80,  78,  65,  73,  65,  72,  85,   1,  66,  61,  73,  75,  81,  79,\n",
      "         11, 103,   0,   0,  29,  72,  62,  81,  79,   9,   1,  46,  75,  79,\n",
      "         65,   9,   1,  36,  81,  67,  75,   9,   1,  61,  74,  64,   1,  40,\n",
      "         69,  72,  85,   1,  72,  61,  81,  67,  68,  65,  64,  11,   1,  48,\n",
      "         68,  65,   1,  80,  78,  61,  69,  74,   1,  62,  65,  67,  61,  74,\n",
      "          1,  80,  75,   1,  73,  75,  78,  65,   9,   1,  61,  74,  64,   1,\n",
      "         36,  61,  78,  78,  85,   1,  83,  61,  72,  71,  65,  64,   1,  61,\n",
      "         72,  75,  74,  67,  79,  69,  64,  65,   1,  69,  80,   9,   1,  83,\n",
      "         61,  80,  63,  68,  69,  74,  67,   1,  68,  69,  79,   1,  79,  75,\n",
      "         74,   5,  79,   1,  80,  68,  69,  74,   1,  66,  61,  63,  65,   9,\n",
      "          1,  61,  72,  78,  65,  61,  64,  85,   1,  61,  62,  72,  61,  86,\n",
      "         65,   1,  83,  69,  80,  68,   1,  65,  84,  63,  69,  80,  65,  73,\n",
      "         65,  74,  80,  11,   1,  36,  61,  78,  78,  85,   1,  71,  65,  76,\n",
      "         80,   1,  79,  73,  69,  72,  69,  74,  67,   1,  61,  74,  64,   1,\n",
      "         83,  61,  82,  69,  74,  67,   9,   1,  65,  82,  65,  74,   1,  80,\n",
      "         68,  75,  81,  67,  68,   1,  69,  80,   1,  83,  61,  79,   1,  72,\n",
      "         69,  71,  65,   1,  61,   1,  72,  69,  80,  80,  72,  65,   1,  62,\n",
      "         65,  78,  65,  61,  82,  65,  73,  65,  74,  80,   9,   1,  83,  61,\n",
      "         80,  63,  68,  69,  74,  67,   1,  68,  69,  79,   1,  79,  75,  74,\n",
      "          1,  67,  72,  69,  64,  65,   1,  61,  83,  61,  85,   1,  66,  78,\n",
      "         75,  73,   1,  68,  69,  73,  11,   1,  11,   1,  11,   1,  11,   0,\n",
      "          0,  48,  68,  65,   1,  72,  61,  79,  80,   1,  80,  78,  61,  63,\n",
      "         65,   1,  75,  66,   1,  79,  80,  65,  61,  73,   1,  65,  82,  61,\n",
      "         76,  75,  78,  61,  80,  65,  64,   1,  69,  74,   1,  80,  68,  65,\n",
      "          1,  61,  81,  80,  81,  73,  74,   1,  61,  69,  78,  11,   1,  48,\n",
      "         68,  65,   1,  80,  78,  61,  69,  74,   1,  78,  75,  81,  74,  64,\n",
      "         65,  64,   1,  61,   1,  63,  75,  78,  74,  65,  78,  11,   1,  36,\n",
      "         61,  78,  78,  85,   5,  79,   1,  68,  61,  74,  64,   1,  83,  61,\n",
      "         79,   1,  79,  80,  69,  72,  72,   1,  78,  61,  69,  79,  65,  64,\n",
      "          1,  69,  74,   1,  66,  61,  78,  65,  83,  65,  72,  72,  11,   0,\n",
      "          0, 102,  36,  65,   5,  72,  72,   1,  62,  65,   1,  61,  72,  78,\n",
      "         69,  67,  68,  80,   9, 103,   1,  73,  81,  78,  73,  81,  78,  65,\n",
      "         64,   1,  35,  69,  74,  74,  85,  11,   0,   0,  29,  79,   1,  36,\n",
      "         61,  78,  78,  85,   1,  72,  75,  75,  71,  65,  64,   1,  64,  61,\n",
      "         80,   1,  68,  65,  78,   9,   1,  68,  65,   1,  72,  75,  83,  65,\n",
      "         78,  65,  64,   1,  68,  69,  79,   1,  68,  61,  74,  64,   1,  61,\n",
      "         62,  79,  65,  74,  80,  73,  69,  74,  64,  65,  64,  72,  85,   1,\n",
      "         61,  74,  64,   1,  80,  75,  81,  63,  68,  65,  64,   1,  80,  68,\n",
      "         65,   1,  72,  69,  67,  68,  80,  74,  69,  74,  67,   1,  79,  63,\n",
      "         61,  78,   1,  75,  74,   1,  68,  69,  79,   1,  66,  75,  78,  65,\n",
      "         68,  65,  61,  64,  11,   0,   0, 102,  37,   1,  71,  74,  75,  83,\n",
      "          1,  68,  65,   1,  83,  69,  72,  72,  11, 103,   0,   0,  48,  68,\n",
      "         65,   1,  79,  63,  61,  78,   1,  68,  61,  64,   1,  74,  75,  80,\n",
      "          1,  76,  61,  69,  74,  65,  64,   1,  36,  61,  78,  78,  85,   1,\n",
      "         66,  75,  78,   1,  74,  69,  74,  65,  80,  65,  65,  74,   1,  85,\n",
      "         65,  61,  78,  79,  11,   1,  29,  72,  72,   1,  83,  61,  79,   1,\n",
      "         83,  65,  72,  72,  11,   0])\n",
      "[11]\n"
     ]
    }
   ],
   "source": [
    "# encode dataset\n",
    "data = torch.tensor(encode(data), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[-1000:])\n",
    "print(encode('.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eab9ec78-18a1-4222-990b-b8ce3b732050",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# split train/val\n",
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a768c3a-aaaa-4a6a-9547-27f7c21a2719",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# block_size\n",
    "torch.manual_seed(42)\n",
    "block_size = 8 # context length\n",
    "batch_size = 4\n",
    "\n",
    "# get a minibatch from train or val split\n",
    "def get_batch(split):\n",
    "    data = train_data if split =='train' else val_data\n",
    "    idx = torch.randint(len(data)-block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in idx])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in idx])\n",
    "    return x,y\n",
    "xb, yb = get_batch('train')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print(yb.shape)\n",
    "print(yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "715f0545-1221-4249-84fa-c66a27baa814",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is [80], target is 75\n",
      "when input is [80, 75], target is 1\n",
      "when input is [80, 75, 1], target is 63\n",
      "when input is [80, 75, 1, 63], target is 75\n",
      "when input is [80, 75, 1, 63, 75], target is 73\n",
      "when input is [80, 75, 1, 63, 75, 73], target is 65\n",
      "when input is [80, 75, 1, 63, 75, 73, 65], target is 1\n",
      "when input is [80, 75, 1, 63, 75, 73, 65, 1], target is 64\n",
      "when input is [65], target is 78\n",
      "when input is [65, 78], target is 1\n",
      "when input is [65, 78, 1], target is 65\n",
      "when input is [65, 78, 1, 65], target is 82\n",
      "when input is [65, 78, 1, 65, 82], target is 65\n",
      "when input is [65, 78, 1, 65, 82, 65], target is 78\n",
      "when input is [65, 78, 1, 65, 82, 65, 78], target is 1\n",
      "when input is [65, 78, 1, 65, 82, 65, 78, 1], target is 79\n",
      "when input is [9], target is 1\n",
      "when input is [9, 1], target is 68\n",
      "when input is [9, 1, 68], target is 61\n",
      "when input is [9, 1, 68, 61], target is 64\n",
      "when input is [9, 1, 68, 61, 64], target is 1\n",
      "when input is [9, 1, 68, 61, 64, 1], target is 62\n",
      "when input is [9, 1, 68, 61, 64, 1, 62], target is 65\n",
      "when input is [9, 1, 68, 61, 64, 1, 62, 65], target is 65\n",
      "when input is [1], target is 66\n",
      "when input is [1, 66], target is 81\n",
      "when input is [1, 66, 81], target is 72\n",
      "when input is [1, 66, 81, 72], target is 72\n",
      "when input is [1, 66, 81, 72, 72], target is 1\n",
      "when input is [1, 66, 81, 72, 72, 1], target is 61\n",
      "when input is [1, 66, 81, 72, 72, 1, 61], target is 64\n",
      "when input is [1, 66, 81, 72, 72, 1, 61, 64], target is 82\n"
     ]
    }
   ],
   "source": [
    "for b in range(batch_size): # batch dimension (which block in the batch)\n",
    "    for t in range(block_size): # time dimension (which token in the block)\n",
    "        print(f'when input is {xb[b, :t+1].tolist()}, target is {yb[b,t]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c95cdf0b-8908-44db-84b8-cba5af449107",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 106])\n",
      "tensor(5.1648, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "QdCuS&]C=Ppk}kQdC<|O[0XAU9RC£;JuM…9';]0gPe4w}}AdC—\n",
      "H'Y`•^BA,\"9u°Zck5:VD0zT/ichS—CL‘oé&YiLk1=z&-oUNis.yW22\n",
      "qcvG&Vf >é((cp](v-yp]»”(W`y\n",
      "Gd0b,¦s :_a{FRrJAgl!-2n g(e;…l–Wu‘dgINbGHKYt53x;`1 4O,•ucK{uLfD`\"g0`3);:8!!.0o/|rnU6?u>léEb3(Q71ZD—ok0t\\v-•\\G}E»/8)Qe[&&Y]7B9-o—o“l;:H.jEsV'°7=–Q9bws3;;`\\:xyu\"°¦¦g|{*bi£«i0t¦\\0tN;Ve»sTZ\">éMJ—[];T«!|q*lupk£VUB/K)y\"Ytor{az]ji0tX1G}E].>’)[f_Q{»F’vé\\Aü—(e4”((”p^b7D9H\\n)”(u»[KQb^LVR\"Z2‘ü(_kq0t*n)7s3…G)I7npD7j«)h0IMBxaBai<^ciü—‘3–;bn «£Sü`*'p’|Y‘*‘CX0\"'.Xx:8[sF}7x8/¦deKy{é…U»7Y7ü'Ee4r9<*\n",
      "<\\¦R{r3F(Aé\n",
      "»W•eNé(nd`4*q5xw\\n5yW\n",
      "\n",
      "G\\3}5/h\n",
      "5|7£kIF9yAj]w(3hTnj«1\n",
      "<{u°M\n",
      "n1eYy<,“[=`—=x;uYyHm_.fR>`xXAa<Uh˜“=rE«E?\"W\"XGr»l B«Qe&322:?Uv-eR-oaO\\3_f&7_zF[Q—lqNZ)6k°h.BI-8£eYC<Uv({?e:01j`SsEYGb,{r{a4&,V.“Y0gFW…h1a1£g££ M«dM…ps?)XnT‘˜niGd*nJX……”E!»W/¦¦yVb^N…lehW8’PW“a4 \n",
      "n7s8JZxz6oü‘oH5—`if4\\?¦^=lupéC•\\ \"Q]F…£G.T^W`c\n",
      "|xA7sow\n",
      "QU»,vYt*dZA?ROo-»B>‘9—o<sw“a•e5[&DH—(;]>p]”°»•,{\n",
      "4Sü^V]-oxw…vMl;Tw:8•T«O60\n",
      "G\\DN“°:0Ti!üP—\n",
      "Q9<z”2_éTjG,^f}FB_ilu[B»I1«O.6W`x_q9y 7I£u–x\\“}}1];`czTwH1Ks»f“N8¦«?GFV\n"
     ]
    }
   ],
   "source": [
    "# simple bigram model\n",
    "torch.manual_seed(42)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size,vocab_size) # read of logits from lookup table (token-wise)\n",
    "    \n",
    "    def forward(self, idx, targets=None):\n",
    "        logits = self.token_embedding_table(idx) # shape: (B,T,C)\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B,T,C = logits.shape\n",
    "            logits = logits.view(B*T,C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n",
    "\n",
    "        \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self.forward(idx) # (B,T,C)\n",
    "            logits = logits[:,-1,:] # last time step only -> (B,C)\n",
    "            probs = F.softmax(logits, dim=-1) # (B,C)\n",
    "            pred = torch.multinomial(probs, num_samples=1) # (B,1)\n",
    "            idx = torch.cat((idx, pred), dim=1) # (B,T+1)\n",
    "        return idx            \n",
    "\n",
    "model = BigramLanguageModel(vocab_size)\n",
    "logits, loss = model.forward(xb,yb) # or out=m(xb,yb) because of __call__ in super() (nn.Module)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "\n",
    "# test\n",
    "idx = torch.zeros((1,1), dtype=torch.long)\n",
    "print(decode(model.generate(idx, max_new_tokens=1000)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a88b73c8-f2f0-4a26-bf5f-8a03e2437e3d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# train the bigram model\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2f678d68-feda-48d5-8737-253860c47907",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.341001510620117\n"
     ]
    }
   ],
   "source": [
    "epochs = 10000\n",
    "batch_size=32\n",
    "for _ in range(epochs):\n",
    "    xb, yb = get_batch('train') # sample batch\n",
    "    logits, loss = model(xb,yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "89ca32ae-a1b0-4c8b-87d9-a0b7e0b83ed8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "“Auratidoo mire tot abling anin, d tud havelangginthan Iton sef ded whesthizin s fe, idancand d towlinoft skind o - haics wan.'Grkhack -he .'shutoristed s t, “Ned ther, tliurng sstodixcicish, hingge oithepemeasular wa fenowalowepsitheyoroorainad tht wourwingrd wa se NGroot …” nd. m bom g’stwe R g arrin tous Dullolumbof Serharer be mis Caindon He fel,’ersithempewidre, ed pp, y, horr, t llin theven ANompe- mby Had nd I aiousoto Lurd y ching joad m pr bed. byoouleas: ais s’\n",
      "'ASidicoulesount thed gheold y. t co I'Thind It, pefren of w stomparpan’d foing ntthed ad, s atid asitchan Ped, onthrcas ly,'re ofre ino id t ly bacuta ke hed t Roby nothedin chearen’les ’temurrmipplou It 1 ba ap,” ngrs l’s. w henin’tt, f…\n",
      "\n",
      "Whe teconifesseanong tou hive peee w at t yercky. lif s ardinthy atan Hangu, hendo wst h g wothalled was Han.\n",
      "\n",
      "\n",
      "I h FIf he lld mily' y.' I hry Hasofond tht thorg e t -beth athend. t tas bunle cle ckng heincoombewastcomer, s, tthels —a ifeing aren I'ORere Hes?”\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "“ONSCooitu Ja y \n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "idx = torch.zeros((1,1), dtype=torch.long)\n",
    "print(decode(model.generate(idx, max_new_tokens=1000)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b929af65-13a3-41ba-82a7-2f02280ae6ef",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5809bd4-7278-4252-b6b8-45b7ef111d9f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
